{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Jupyter Notebooks for the visual analysis of critical choices in Global Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valentina Noacco, Andres Peñuela-Fernandez, Francesca Pianosi, Thorsten Wagener \n",
    "### (University of Bristol)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document provides:\n",
    "* a brief introduction to Global Sensitivity Analysis (GSA);\n",
    "* a workflow to asssess one of the critical choices needed to set up a GSA application. Here we use the SAFE (Sensitivity Analysis For Everybody) toolbox ([References](#References) 1-2).\n",
    "\n",
    "In this example we apply the Regional Sensitivity Analysis GSA method to the rainfall-runoff Hymod model.\n",
    "\n",
    "\n",
    "# PART I: Introduction\n",
    "\n",
    "## What is Global Sensitivity Analysis and why shall we use it?\n",
    "\n",
    "**Global Sensitivity Analysis** is a set of mathematical techniques which investigate how the uncertainty in the model inputs influences the variability of the model outputs ([References](#References) 3-4).\n",
    "\n",
    "The benefits of applying GSA are:\n",
    "\n",
    "* **Better understanding of the model**: Evaluate the model behaviour beyond default set-up\n",
    "    \n",
    "* **“Sanity check” of the model**: Test whether the model \"behaves well\" (model validation)\n",
    "    \n",
    "* **Priorities for uncertainty reduction**: Identify the important inputs on which to focus computationally-intensive calibration, acquisition of new data, etc. \n",
    "    \n",
    "* **More transparent and robust decisions**: Understand how assumptions about uncertain inputs reflect on the modelling outcome and thus on model-informed decisions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Global Sensitivity Analysis works\n",
    "\n",
    "GSA investigates how the uncertainty in the model input factors influences the variability of the model output.\n",
    "\n",
    "An '**input factor**' is any element that can be changed before running the model. In general, input factors could be the model's parameters, forcing input data, but also the very equations implemented in the model or other set-up choices (for instance, the spatial resolution) needed for the model execution on a computer.\n",
    "\n",
    "An '**output**' is any variable that is obtained after the model execution.\n",
    "\n",
    "The main steps to perform GSA are summarised in the figure below.\n",
    "<img src=\"how_GSA_works.png\" width=\"800px\">\n",
    "a. The input factors are sampled from their ranges of variability.\n",
    "\n",
    "b. The model is repeatedly run against each of the input sampled combinations.\n",
    "\n",
    "c. The output samples so obtained can be used to characterise the output uncertainty, for instance through a probability distribution or scatter plots.\n",
    "\n",
    "d. GSA is applied to the input and output samples in order to obtain a set of sensitivity indices. The sensitivity indices measure the relative influence of each input factor on the uncertainty of the output ([References](#References) 4,5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II: Workflow application\n",
    "### Step 1: Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:/Users/valen/OneDrive - University of Bristol/proj_SAFEVAL/SAFEPy/SAFEpython_v0.0.0/SAFEpython'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8b9290f7e09d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmydir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:/Users/valen/OneDrive - University of Bristol/proj_SAFEVAL/SAFEPy/SAFEpython_v0.0.0\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/SAFEpython\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSAFEpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRSA_groups\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mRg\u001b[0m \u001b[1;31m# module to perform RSA with groups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:/Users/valen/OneDrive - University of Bristol/proj_SAFEVAL/SAFEPy/SAFEpython_v0.0.0/SAFEpython'"
     ]
    }
   ],
   "source": [
    "from __future__ import division, absolute_import, print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import widgets\n",
    "\n",
    "# Import SAFE modules:\n",
    "import os\n",
    "mydir = \"C:/Users/valen/OneDrive - University of Bristol/proj_SAFEVAL/SAFEPy/SAFEpython_v0.0.0\"\n",
    "os.chdir(mydir + \"/SAFEpython\")\n",
    "\n",
    "import SAFEpython.RSA_groups as Rg # module to perform RSA with groups\n",
    "import SAFEpython.plot_functions as pf # module to visualize the results\n",
    "from SAFEpython.model_execution import model_execution # module to execute the model\n",
    "from SAFEpython.sampling import AAT_sampling, AAT_sampling_extend # module to perform the input sampling\n",
    "from SAFEpython.util import aggregate_boot  # function to aggregate the bootstrap results\n",
    "from SAFEpython import HyMod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model: Rainfall-runoff Hymod model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying GSA, let's have a brief overview of the HyMod model, which it is a parsimonious rainfall-runoff model based on the theory of runoff yeild under infiltration excess. \n",
    "\n",
    "Hymod (Boyle 2001; Wagener et al. 2001) is composed of a soil moisture accounting routine, and a flow routing routine, which in its turn is composed of a fast and a slow routing pathway.\n",
    "\n",
    "The model structure is illustrated in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<left><img src=\"Hymod_scheme.png\" width=\"700px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following steps will be performed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Setup the model\n",
    "\n",
    "Define: \n",
    "- the input factors whose influence is to be analysed with GSA, \n",
    "- their range of variability (choice made by expert judgement, available data or previous studies),\n",
    "- choice of their distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 5 # number of input factors\n",
    "N = 2000 # number of samples\n",
    "distr_par  = [np.nan] * M\n",
    "col_names  = [\"$S_M$\" , \"$beta$\" , \"$alpha$\", \"$R_s$\", \"$R_F$\"] # input factors of interest\n",
    "distr_fun  = st.uniform # uniform distribution\n",
    "samp_strat = 'lhs' # Latin Hypercube\n",
    "fun_test   = HyMod.hymod_MulObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range of variability\n",
    "data = [[\"mm\", 1,   400, \"Maximum storage capacity\"],\n",
    "        [\"-\",  0,   2,   \"Degree of spatial variability of the $S_M$\"],\n",
    "        [\"-\",  0,   1,   \"Factor distributing slow and quick flows\"],\n",
    "        [\"-\",  0,   0.1, \"Fractional discharge of the slow release reservoir\"],\n",
    "        [\"-\",  0.1, 1,   \"Fractional discharge of the quick release reservoirs\"]]\n",
    "model_inputs = pd.DataFrame(data, \n",
    "                           columns=[\"Unit\", \"Min value\", \"Max value\", \"Description\"],\n",
    "                           index = col_names)\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "C:/Users/valen/OneDrive - University of Bristol/proj_SAFEVAL/SAFEPy/SAFEpython_v0.0.0/data/LeafCatch.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-431358b38c4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load data:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydir\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'/data/LeafCatch.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m365\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 1-year simulation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mevap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m365\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mflow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m365\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andro\\onedrive - university of bristol\\andresfrancesca\\mat\\jupyter notebooks\\safe-notebooks\\env\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[0;32m   1742\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1743\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1744\u001b[1;33m             \u001b[0mfhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1745\u001b[0m             \u001b[0mown_fhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1746\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andro\\onedrive - university of bristol\\andresfrancesca\\mat\\jupyter notebooks\\safe-notebooks\\env\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andro\\onedrive - university of bristol\\andresfrancesca\\mat\\jupyter notebooks\\safe-notebooks\\env\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    622\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    623\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: C:/Users/valen/OneDrive - University of Bristol/proj_SAFEVAL/SAFEPy/SAFEpython_v0.0.0/data/LeafCatch.txt not found."
     ]
    }
   ],
   "source": [
    "# Load data:\n",
    "data = np.genfromtxt(mydir +'/data/LeafCatch.txt', comments='%')\n",
    "rain = data[0:365, 0] # 1-year simulation\n",
    "evap = data[0:365, 1]\n",
    "flow = data[0:365, 2]\n",
    "warmup = 30 # Model warmup period (days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class setup_model:\n",
    "    def __init__(self, x1, x2, x3, x4, x5):\n",
    "        # The shape parameters of the uniform distribution are the lower limit and \n",
    "        # the difference between lower and upper limits:\n",
    "        self.xmin = [x1.value[0], x2.value[0], x3.value[0], x4.value[0], x5.value[0]]\n",
    "        self.xmax = [x1.value[1], x2.value[1], x3.value[1], x4.value[1], x5.value[1]]\n",
    "        for i in range(M):\n",
    "            distr_par[i] = [self.xmin[i], self.xmax[i] - self.xmin[i]]\n",
    "        self.distr_par = distr_par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Sample inputs space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of model runs (N) typically increases proportionally to the number of input factors ($M$) and will depend on the GSA methods chosen as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sample_input:\n",
    "    def __init__(self,distr_par):\n",
    "        self.X = AAT_sampling(samp_strat, M, distr_fun, distr_par, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sampled input factors combination, we run the model and save the associated model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class run_model:\n",
    "    def __init__(self,X):\n",
    "        self.Y = model_execution(fun_test, X, rain, evap, flow, warmup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Apply Sensitivity Analysis (RSA) method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RSA requires to sort the output samples and then to split them into a certain number of groups (defined by the user). Afterwards, RSA identifies the sub-samples in the inputs space that produced the outputs in each group and compute the cumulative distribution function (CDF) of each sub-sample. Finally, the sensitivity indices are defined as the (mean) maximum vertical distance between the CDFs of the various groups.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we divide the output samples into 10 groups, where each group contains the same number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSA_method:\n",
    "    def __init__(self,X,Y): \n",
    "        mvd_median, mvd_mean, mvd_max, spread_median, spread_mean, spread_max, self.idx, self.Yk = \\\n",
    "        Rg.RSA_indices_groups(X, Y, ngroup=10, Nboot=0)\n",
    "\n",
    "        self.mvd_p = pd.DataFrame(mvd_median,columns=[\"y\"])\n",
    "        Xdf = pd.DataFrame(X,columns=[col_names])\n",
    "        xx = pd.melt(Xdf)\n",
    "        Ydf = pd.DataFrame(Y,columns=[\"y\"])\n",
    "        yy = pd.concat([Ydf]*M,ignore_index=True)\n",
    "        self.new_data = pd.concat([xx,yy],axis=1)\n",
    "        self.new_data.columns = [\"Input\",\"x\",\"y\"]\n",
    "        all_ind = np.concatenate((self.idx,self.idx,self.idx,self.idx,self.idx),axis=0)\n",
    "        all_ind = pd.DataFrame(all_ind,columns=['idx'])\n",
    "        self.new_data['idx'] = all_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Check model behaviour by visualising input/output samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplots are plotted to visualise the behaviour of the output over each input factor in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of interactivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_figures(change):\n",
    "    with fig.batch_update():\n",
    "        distr_par = setup_model(x1, x2, x3, x4, x5).distr_par\n",
    "        X = sample_input(distr_par).X\n",
    "        Y = run_model(X).Y[:,0]\n",
    "        new_data = RSA_method(X,Y).new_data\n",
    "        fig.data[0].x = new_data.loc[new_data['Input'] == model_inputs.index[0], 'x']    \n",
    "        fig.data[1].x = new_data.loc[new_data['Input'] == model_inputs.index[1], 'x']    \n",
    "        fig.data[2].x = new_data.loc[new_data['Input'] == model_inputs.index[2], 'x']\n",
    "        fig.data[3].x = new_data.loc[new_data['Input'] == model_inputs.index[3], 'x']\n",
    "        fig.data[4].x = new_data.loc[new_data['Input'] == model_inputs.index[4], 'x']\n",
    "        fig.data[0].marker.color = new_data.loc[new_data['Input'] == model_inputs.index[0], 'idx']\n",
    "        fig.data[1].marker.color = new_data.loc[new_data['Input'] == model_inputs.index[1], 'idx']    \n",
    "        fig.data[2].marker.color = new_data.loc[new_data['Input'] == model_inputs.index[2], 'idx']\n",
    "        fig.data[3].marker.color = new_data.loc[new_data['Input'] == model_inputs.index[3], 'idx']\n",
    "        fig.data[4].marker.color = new_data.loc[new_data['Input'] == model_inputs.index[4], 'idx']\n",
    "        fig.data[0].y = new_data.loc[new_data['Input'] == model_inputs.index[0], 'y']    \n",
    "        fig.data[1].y = new_data.loc[new_data['Input'] == model_inputs.index[1], 'y']    \n",
    "        fig.data[2].y = new_data.loc[new_data['Input'] == model_inputs.index[2], 'y']\n",
    "        fig.data[3].y = new_data.loc[new_data['Input'] == model_inputs.index[3], 'y']\n",
    "        fig.data[4].y = new_data.loc[new_data['Input'] == model_inputs.index[4], 'y']\n",
    "        fig.layout.barmode = 'overlay'\n",
    "        #fig.update_xaxes(matches=None)\n",
    "\n",
    "        mvd_p = RSA_method(X,Y).mvd_p\n",
    "        for i in range(0,5):\n",
    "            fig1.data[i].y = np.array(mvd_p.y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the sliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = widgets.FloatRangeSlider(value = [50, 150], min = 0, max = 200, step = 1, description = model_inputs.index[0], \n",
    "                              readout_format = '.1f', continuous_update=False)\n",
    "x1.observe(update_figures,names = 'value')\n",
    "\n",
    "x2 = widgets.FloatRangeSlider(value = [0.5, 1.5], min = 0, max = 2, step = 0.1, description = model_inputs.index[1], \n",
    "                              readout_format = '.1f', continuous_update=False)\n",
    "x2.observe(update_figures,names = 'value')\n",
    "\n",
    "x3 = widgets.FloatRangeSlider(value = [0.2, 0.8], min = 0, max = 1, step = 0.1, description = model_inputs.index[2], \n",
    "                              readout_format = '.1f', continuous_update=False)\n",
    "x3.observe(update_figures,names = 'value')\n",
    "\n",
    "x4 = widgets.FloatRangeSlider(value = [0.02, 0.08], min = 0, max = 0.1, step = 0.01, description = model_inputs.index[3], \n",
    "                              readout_format = '.1f', continuous_update=False)\n",
    "x4.observe(update_figures,names = 'value')\n",
    "\n",
    "x5 = widgets.FloatRangeSlider(value = [0.2, 0.8], min = 0, max = 1, step = 0.1, description = model_inputs.index[4], \n",
    "                              readout_format = '.1f', continuous_update=False)\n",
    "x5.observe(update_figures,names = 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\andro\\onedrive - university of bristol\\andresfrancesca\\mat\\jupyter notebooks\\safe-notebooks\\env\\lib\\site-packages\\SAFEpython\\util.py:24: NumbaWarning:\n",
      "\n",
      "\u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"empiricalcdf\" failed type inference due to: \u001b[1mUntyped global name 'isinstance':\u001b[0m \u001b[1m\u001b[1mcannot determine Numba type of <class 'builtin_function_or_method'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"env\\lib\\site-packages\\SAFEpython\\util.py\", line 72:\u001b[0m\n",
      "\u001b[1mdef empiricalcdf(x, xi):\n",
      "    <source elided>\n",
      "    ###########################################################################\n",
      "\u001b[1m    if not isinstance(x, np.ndarray):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "c:\\users\\andro\\onedrive - university of bristol\\andresfrancesca\\mat\\jupyter notebooks\\safe-notebooks\\env\\lib\\site-packages\\SAFEpython\\util.py:24: NumbaWarning:\n",
      "\n",
      "\u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"empiricalcdf\" failed type inference due to: \u001b[1mUntyped global name 'isinstance':\u001b[0m \u001b[1m\u001b[1mcannot determine Numba type of <class 'builtin_function_or_method'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"env\\lib\\site-packages\\SAFEpython\\util.py\", line 72:\u001b[0m\n",
      "\u001b[1mdef empiricalcdf(x, xi):\n",
      "    <source elided>\n",
      "    ###########################################################################\n",
      "\u001b[1m    if not isinstance(x, np.ndarray):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "c:\\users\\andro\\onedrive - university of bristol\\andresfrancesca\\mat\\jupyter notebooks\\safe-notebooks\\env\\lib\\site-packages\\numba\\object_mode_passes.py:178: NumbaWarning:\n",
      "\n",
      "\u001b[1mFunction \"empiricalcdf\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"env\\lib\\site-packages\\SAFEpython\\util.py\", line 72:\u001b[0m\n",
      "\u001b[1mdef empiricalcdf(x, xi):\n",
      "    <source elided>\n",
      "    ###########################################################################\n",
      "\u001b[1m    if not isinstance(x, np.ndarray):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\n",
      "c:\\users\\andro\\onedrive - university of bristol\\andresfrancesca\\mat\\jupyter notebooks\\safe-notebooks\\env\\lib\\site-packages\\numba\\object_mode_passes.py:188: NumbaDeprecationWarning:\n",
      "\n",
      "\u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"env\\lib\\site-packages\\SAFEpython\\util.py\", line 72:\u001b[0m\n",
      "\u001b[1mdef empiricalcdf(x, xi):\n",
      "    <source elided>\n",
      "    ###########################################################################\n",
      "\u001b[1m    if not isinstance(x, np.ndarray):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distr_par = setup_model(x1, x2, x3, x4, x5).distr_par\n",
    "X = sample_input(distr_par).X\n",
    "Y = run_model(X).Y[:,0]\n",
    "new_data = RSA_method(X,Y).new_data\n",
    "p = px.scatter(new_data, x = \"x\", y = 'y', facet_col = \"Input\",color=\"idx\", \n",
    "               color_continuous_scale = px.colors.diverging.RdYlBu[::-1],\n",
    "               width=1000, height=500)\n",
    "fig = go.FigureWidget(data=p, layout=go.Layout(barmode='overlay'))\n",
    "fig.update_xaxes(title_text = \"\")\n",
    "fig.update_xaxes(matches=None)\n",
    "fig.layout.yaxis.title=\"Y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Plot sensitivity indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sensitivity indices for the RSA method are the maximum vertical distances over each pair of CDF.\n",
    "\n",
    "Definition of the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "mvd_p = RSA_method(X,Y).mvd_p\n",
    "p1 = px.scatter(mvd_p, x = [\"$S_M$\" , \"$beta$\" , \"$alpha$\", \"$R_s$\", \"$R_F$\"], y = 'y',\n",
    "                color=['red','blue','green',\"magenta\",\"cyan\"], width=600, height=300)\n",
    "\n",
    "fig1  = go.FigureWidget(data=p1,layout=go.Layout(barmode='overlay'))\n",
    "fig1.layout.yaxis.range=[0,1]\n",
    "fig1.layout.yaxis.title=\"Maximum Vertical Distance\"\n",
    "fig1.layout.xaxis.title=\"\"\n",
    "fig1.update_traces(marker=dict(size=20),showlegend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the interactive figures + sliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b315b3f95a0448a292b8452335a1c4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(FloatRangeSlider(value=(50.0, 150.0), continuous_update=False, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.VBox([widgets.HBox([widgets.VBox([x1,x2,x3,x4,x5]),fig1]), fig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Assess robustness by bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to assess the robustness of the estimated sensitivity indices, bootstrapping is performed (here we resample 100 times). The 95% confidence intervals of the sensitivity indices are plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arguments should have the same length. The length of column argument `df[y]` is 5, whereas the length of previous arguments ['x'] is 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-79e075805f09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmvd_ub_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmvd_ub\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mfig2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmvd_m_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"x1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"x2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"x3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mfig2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_scatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmvd_lb_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"x1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"x2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"x3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'green'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"markers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mfig2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_scatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmvd_ub_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"x1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"x2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"x3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'green'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"markers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andro\\onedrive - university of bristol\\andresfrancesca\\mat\\jupyter notebooks\\safe-notebooks\\env\\lib\\site-packages\\plotly\\express\\_chart_types.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(data_frame, x, y, color, symbol, size, hover_name, hover_data, custom_data, text, facet_row, facet_col, facet_col_wrap, error_x, error_x_minus, error_y, error_y_minus, animation_frame, animation_group, category_orders, labels, color_discrete_sequence, color_discrete_map, color_continuous_scale, range_color, color_continuous_midpoint, symbol_sequence, symbol_map, opacity, size_max, marginal_x, marginal_y, trendline, trendline_color_override, log_x, log_y, range_x, range_y, render_mode, title, template, width, height)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mmark\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;36m2\u001b[0m\u001b[0mD\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \"\"\"\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmake_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andro\\onedrive - university of bristol\\andresfrancesca\\mat\\jupyter notebooks\\safe-notebooks\\env\\lib\\site-packages\\plotly\\express\\_core.py\u001b[0m in \u001b[0;36mmake_figure\u001b[1;34m(args, constructor, trace_patch, layout_patch)\u001b[0m\n\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     args, trace_specs, grouped_mappings, sizeref, show_colorbar = infer_config(\n\u001b[1;32m-> 1172\u001b[1;33m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrace_patch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1173\u001b[0m     )\n\u001b[0;32m   1174\u001b[0m     \u001b[0mgrouper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mone_group\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouped_mappings\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mone_group\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andro\\onedrive - university of bristol\\andresfrancesca\\mat\\jupyter notebooks\\safe-notebooks\\env\\lib\\site-packages\\plotly\\express\\_core.py\u001b[0m in \u001b[0;36minfer_config\u001b[1;34m(args, constructor, trace_patch)\u001b[0m\n\u001b[0;32m   1026\u001b[0m             \u001b[0mall_attrables\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgroup_attr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_attrables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_attrables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattrables\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andro\\onedrive - university of bristol\\andresfrancesca\\mat\\jupyter notebooks\\safe-notebooks\\env\\lib\\site-packages\\plotly\\express\\_core.py\u001b[0m in \u001b[0;36mbuild_dataframe\u001b[1;34m(args, attrables, array_attrables)\u001b[0m\n\u001b[0;32m    954\u001b[0m                             \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margument\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m                             \u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    957\u001b[0m                         )\n\u001b[0;32m    958\u001b[0m                     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arguments should have the same length. The length of column argument `df[y]` is 5, whereas the length of previous arguments ['x'] is 3"
     ]
    }
   ],
   "source": [
    "# Compute sensitivity indices with confidence intervals using bootstrapping\n",
    "Nboot = 100\n",
    "# Warning: the following line may take some time to run, as the computation of\n",
    "# CDFs is costly:\n",
    "mvd_median, mvd_mean, mvd_max, spread_median, spread_mean, spread_max, idx, Yk = \\\n",
    "    Rg.RSA_indices_groups(X, Y, ngroup=10, Nboot=100)\n",
    "\n",
    "# Compute mean and confidence intervals of the sensitivity indices (mvd,\n",
    "# maximum vertical distance) across the bootstrap resamples:\n",
    "mvd_m, mvd_lb, mvd_ub = aggregate_boot(mvd_median) # shape (M,)\n",
    "\n",
    "mvd_m_p = pd.DataFrame(mvd_m,columns=[\"y\"])\n",
    "mvd_lb_p = pd.DataFrame(mvd_lb,columns=[\"y\"])\n",
    "mvd_ub_p = pd.DataFrame(mvd_ub,columns=[\"y\"])\n",
    "\n",
    "fig2 = px.scatter(mvd_m_p, x = [\"x1\",\"x2\", \"x3\"], y = 'y',color=['black','black','black'], width=600, height=400)\n",
    "fig2.add_scatter(y = mvd_lb_p.y, x = [\"x1\",\"x2\", \"x3\"], marker=dict(color=['red','blue','green']), mode = \"markers\")\n",
    "fig2.add_scatter(y = mvd_ub_p.y, x = [\"x1\",\"x2\", \"x3\"], marker=dict(color=['red','blue','green']), mode = \"markers\")\n",
    "\n",
    "fig2.layout.yaxis.range=[0,1]\n",
    "fig2.layout.yaxis.title=\"Maximum Vertical Distance\"\n",
    "fig2.layout.xaxis.title=\"\"\n",
    "fig2.update_traces(marker=dict(size=16),showlegend=False)\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Visualise input factors interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to investigate the interactions between input factors we plot one input against the other, coloured by the value taken by the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inter = pd.concat([pd.DataFrame(X),pd.DataFrame(Y)],axis=1)\n",
    "data_inter.columns = ['x1', 'x2', 'x3', 'y']\n",
    "# index_vals = data_colscat['idx'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = go.Figure(data=go.Splom(\n",
    "                dimensions=[dict(label='x1',\n",
    "                                 values=data_inter['x1']),\n",
    "                            dict(label='x2',\n",
    "                                 values=data_inter['x2']),\n",
    "                            dict(label='x3',\n",
    "                                 values=data_inter['x3'])],\n",
    "                showupperhalf=False, # remove plots on diagonal\n",
    "                text=data_inter['y'],\n",
    "                marker=dict(color=data_inter['y'],colorbar=dict(title=\"Y\"),\n",
    "                            showscale=True, # colors encode categorical variables\n",
    "                            line_color='white', line_width=0.5,colorscale = px.colors.diverging.RdYlBu[::-1])\n",
    "                ))\n",
    "\n",
    "fig3.show()                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we visualise interactions between inputs through parallel coordinate plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group = pd.concat([pd.DataFrame(X),pd.DataFrame(Y),pd.DataFrame(idx)],axis=1)\n",
    "data_group.columns = ['x1', 'x2', 'x3', 'y','idx']\n",
    "\n",
    "fig4 = px.parallel_coordinates(data_group, color=\"y\", dimensions=['x1','x2','x3','y'],\n",
    "                             color_continuous_scale=px.colors.diverging.RdYlBu[::-1],\n",
    "                             color_continuous_midpoint=2)\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"References\"></a>References\n",
    "\n",
    "\n",
    "RSA is based on the function created as part of the SAFE Toolbox by F. Pianosi, F. Sarrazin and T. Wagener at Bristol University (2015). Please refer to the `Licence` file in the SAFE toolbox. \n",
    "\n",
    "1) [SAFE Toolbox Website](https://www.safetoolbox.info/)\t\n",
    "\n",
    "2) [Introductory paper to SAFE - Pianosi et al. (2015)](https://www.sciencedirect.com/science/article/pii/S1364815215001188)\n",
    "\n",
    "3) [A review of available methods and workflows for Sensitivity Analysis - Pianosi et al. (2016)](https://www.sciencedirect.com/science/article/pii/S1364815216300287)\n",
    "\n",
    "4) [What has Global Sensitivity Analysis ever done for us? A systematic review to support scientific advancement and to inform policy-making in earth system modelling - Wagener and Pianosi (2019)](https://www.sciencedirect.com/science/article/pii/S0012825218300990)\n",
    "\n",
    "5) [Practical guide through the critical choices needed for Global Sensitivity Analysis - Noacco et al. (2019)](https://www.sciencedirect.com/science/article/pii/S2215016119302572?via%3Dihub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
